# 🎓 初心者向け：モデル学習の仕組み解説

このドキュメントでは、オノマトペMLPモデルがどのように学習されたかを、初心者にもわかりやすく解説します。

---

## 📚 目次

1. [学習の全体像](#学習の全体像)
2. [ステップ1: データセットの準備](#ステップ1-データセットの準備)
3. [ステップ2: オノマトペを数値に変換](#ステップ2-オノマトペを数値に変換)
4. [ステップ3: モデルの構造](#ステップ3-モデルの構造)
5. [ステップ4: 学習のプロセス](#ステップ4-学習のプロセス)
6. [ステップ5: モデルの評価](#ステップ5-モデルの評価)
7. [実際のコード例](#実際のコード例)

---

## 🎯 学習の全体像

### 簡単な例え話

**料理のレシピを学習する料理人**を想像してください。

```
料理人（モデル）が学習すること：
「このオノマトペ（例：ガンガン）の時は、
 どんな味付け（DSPパラメータ）をすればいいか？」

学習方法：
1. 先輩料理人が作った「お手本レシピ」を1000個以上見る
2. パターンを覚える（例：「ガンガン」→低音を強く、音量を大きく）
3. 新しいオノマトペが来ても、学習したパターンから推測できるようになる
```

---

## ステップ1: データセットの準備

### 📊 何を準備したか？

**1,300個のデータセット**を作成しました。各データは：

```
1つのデータ = {
  オノマトペ: "ガンガン",
  正解のDSPパラメータ: [0.6, 0.5, 0.3, 0.5, ...]  ← 10個の数値
}
```

### 具体例

```
データ1: ガンガン → [0.6, 0.5, 0.3, 0.5, 0.4, 0.2, -0.1, 0.8, 0.3, 0.0]
         ↑強い音   ↑低音強調、音量大きめ、鋭いアタック

データ2: サラサラ → [-0.2, -0.3, -0.2, -0.3, 0.2, 0.5, 0.7, -0.5, 0.5, 0.1]
         ↑軽い音   ↑低音カット、高音強調、柔らかいアタック

データ3: キラキラ → [-0.3, -0.4, -0.5, -0.4, 0.1, 0.7, 0.9, -0.2, 0.6, 0.15]
         ↑煌めく   ↑超高音強調、音量控えめ
```

### どうやって作った？

**テンプレート方式**を使用：

```python
# 「ガンガン」のテンプレート
'ガンガン': [0.6, 0.5, 0.3, 0.5, 0.4, 0.2, -0.1, 0.8, 0.3, 0.0]

# これを基に、少しランダムにバリエーションを作る
'ガンガン' + 音源1 → [0.62, 0.48, 0.31, ...]  ← 少し変化
'ガンガン' + 音源2 → [0.58, 0.52, 0.29, ...]  ← 少し変化
```

### 📁 データの分割

モデルの性能を正しく評価するため、データを3つに分けました：

```
全データ (1,300個)
├── 訓練データ (70% = 910個)    ← モデルが学習に使う
├── 検証データ (15% = 195個)    ← 学習中の調整に使う
└── テストデータ (15% = 195個)  ← 最終評価に使う（学習には使わない！）
```

**重要**: テストデータは学習に一切使わず、最後の評価だけに使います。これにより、モデルが「暗記」ではなく「理解」しているか確認できます。

---

## ステップ2: オノマトペを数値に変換

### 🔤 なぜ変換が必要？

コンピュータは文字を直接理解できません。数値に変換する必要があります。

### 変換の流れ

```
「ガンガン」
   ↓ ① カタカナ → 音素列
['g', 'a', 'N', 'g', 'a', 'N']
   ↓ ② 音素列 → モーラ列
['ga', 'N', 'ga', 'N']
   ↓ ③ モーラ列 → 特徴量（38個の数値）
[4.0, 2.0, 2.0, 2.0, 0.0, 0.0, ...]
```

### 📐 38個の特徴量とは？

オノマトペの「音の特徴」を38個の数値で表します：

#### グループA: 全体の構造（6個）
```
1. モーラ数: 4個（ga, N, ga, N）
2. 子音の数: 2個（g, g）
3. 母音の数: 2個（a, a）
4. 繰り返し回数: 2回（「ガン」が2回）
5. 同じモーラの塊の数: 0個
6. 繰り返しの比率: 0.0
```

#### グループB: 長さ・アクセント（4個）
```
7. 促音（ッ）の数: 0個
8. 長音（ー）の数: 0個
9. 長音の比率: 0.0
10. 語末が長音か: いいえ（0）
```

#### グループC: 母音の種類（5個）
```
11. 「a」の数: 2個  ← 「ガンガン」はa音
12. 「i」の数: 0個
13. 「u」の数: 0個
14. 「e」の数: 0個
15. 「o」の数: 0個
```

#### グループD: 子音の種類（6個）
```
16. 無声破裂音（p, t, k）: 0個
17. 有声破裂音（g, d, b）: 2個  ← 「ガンガン」のg
18. 無声摩擦音（s, sh, h）: 0個
19. 有声摩擦音（z, j）: 0個
20. 鼻音（m, n, N）: 2個  ← 「ガンガン」のN
21. 流音・半母音（r, w, y）: 0個
```

#### グループE: 子音の比率（3個）
```
22. 破裂音+摩擦音の比率: 0.5
23. 有声子音の比率: 0.5
24. 鼻音の比率: 0.5
```

#### グループF: 位置情報（14個）
```
25-30. 語頭の子音カテゴリ（6個、ワンホット）
31-36. 語末の子音カテゴリ（6個、ワンホット）
37. 母音で始まるか: いいえ（0）
38. 母音で終わるか: いいえ（0）
```

### 🎨 視覚化

```
「ガンガン」の特徴量ベクトル（一部）:
[4, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, ...]
 ↑  ↑  ↑  ↑           ↑              ↑
 モ 子 母 繰         a音            有声破裂音
 │  音 音 り          の              の数
 ラ の の 返          数
 数 数 数 し

「キラキラ」の特徴量ベクトル（一部）:
[4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, ...]
 ↑  ↑  ↑  ↑           ↑              ↑
 4  4  4  2            0               0
 モ 子 母 繰         a音なし        破裂音なし
 │  音 音 り         i音が4個
 ラ
```

**ポイント**:
- 「ガンガン」は `g` 音（有声破裂音）と `a` 音が特徴
- 「キラキラ」は `k` 音と `i` 音が特徴
- この違いがモデルに伝わります！

---

## ステップ3: モデルの構造

### 🧠 MLP（多層パーセプトロン）とは？

**「多層パーセプトロン」**は、人間の脳の神経細胞（ニューロン）を真似た仕組みです。

### 簡単な例え

```
工場の組み立てライン：

入力（38個の数値）
    ↓
[第1工程] 32人の作業員が並んで処理
    ↓
[第2工程] 10個の最終製品を作る
    ↓
出力（10個のDSPパラメータ）
```

### 📊 実際の構造

```
入力層（38次元）
    ↓
    │ [重み×38×32個]
    ↓
隠れ層（32ニューロン）
    ↓ ReLU（活性化関数）
    │ [重み×32×10個]
    ↓
出力層（10次元）
    ↓ Tanh（-1〜+1に制限）
    ↓
出力（DSPパラメータ）
```

### 🔢 計算の流れ

```python
# 入力: オノマトペの特徴量
input = [4, 2, 2, 2, 0, 0, ...]  # 38個

# 第1層: 入力 × 重み1 → 隠れ層
hidden = ReLU(input × weight1)  # 32個の数値

# 第2層: 隠れ層 × 重み2 → 出力
output = Tanh(hidden × weight2)  # 10個の数値

# 出力例
output = [0.6, 0.5, 0.3, ...]  # DSPパラメータ
```

### 🎛️ 重み（Weight）とは？

**重み**は、モデルが学習する「パラメータ」です。

```
例えば：
- 「有声破裂音の数」の重みが大きい
  → 「g」音が多いと低音を強くする

- 「i音の数」の重みが大きい
  → 「i」音が多いと高音を強くする
```

**学習 = この重みを調整すること**

---

## ステップ4: 学習のプロセス

### 📖 学習の仕組み

モデルは「試行錯誤」を繰り返して学習します。

### ステップバイステップ

#### 1. 初期状態（ランダムな重み）

```
入力: 「ガンガン」の特徴量
モデル: ランダムな予測 → [0.1, -0.2, 0.5, ...]
正解: [0.6, 0.5, 0.3, ...]
誤差: とても大きい！
```

#### 2. 誤差を計算

```python
# MSE（平均二乗誤差）
error = mean((予測 - 正解)²)

例:
予測 = [0.1, -0.2, 0.5, ...]
正解 = [0.6,  0.5, 0.3, ...]
誤差 = ((0.1-0.6)² + (-0.2-0.5)² + (0.5-0.3)² + ...) / 10
     = (0.25 + 0.49 + 0.04 + ...) / 10
     = 0.234  ← この誤差を小さくしたい
```

#### 3. 重みを調整（逆伝播）

```
誤差が大きい
    ↓
どの重みが悪かったか計算
    ↓
重みを少し変更
    ↓
誤差が小さくなる！
```

#### 4. 繰り返す（エポック）

```
エポック1: 全データで学習 → 誤差 = 0.25
エポック2: 全データで学習 → 誤差 = 0.21
エポック3: 全データで学習 → 誤差 = 0.18
...
エポック150: 全データで学習 → 誤差 = 0.01
```

### 🎯 学習の過程（実際のログ）

```
Epoch 1/150 - Train Loss: 0.2521, Val Loss: 0.2089
  ↑ まだ誤差が大きい

Epoch 50/150 - Train Loss: 0.0234, Val Loss: 0.0245
  ↑ かなり良くなってきた

Epoch 100/150 - Train Loss: 0.0112, Val Loss: 0.0121
  ↑ もっと良くなった

Epoch 150/150 - Train Loss: 0.0109, Val Loss: 0.0115
  ↑ ほぼ収束！
```

### 📉 学習曲線

```
誤差
 ↑
0.3 |●
    |  ●
0.2 |    ●
    |      ●
0.1 |        ●
    |          ●●●
0.0 |_______________●●●●→ エポック
    0   50  100  150
```

---

## ステップ5: モデルの評価

### ✅ どうやって性能を測る？

#### 1. MSE（平均二乗誤差）

**誤差の平均** - 小さいほど良い

```
MSE = 0.0109  ← とても小さい = 良いモデル
```

#### 2. R²スコア（決定係数）

**どれだけ正確に予測できるか** - 1.0に近いほど良い

```
R² = 0.824  ← 82.4%の精度 = かなり良い

意味:
- 1.0 = 完璧な予測
- 0.8 = かなり良い予測
- 0.5 = まあまあ
- 0.0 = 平均値を言っているだけ（役に立たない）
```

#### 3. 符号の正解率

**方向性が合っているか**（増やすべき時に増やせているか）

```
Sign Accuracy = 95.4%  ← ほぼ正しい方向
```

### 📊 各パラメータの精度

```
Parameter            MSE      R²
------------------------------------
gain                 0.0082   0.947  ← とても良い
compression          0.0122   0.934  ← とても良い
eq_sub               0.0120   0.944  ← とても良い
eq_low               0.0102   0.939  ← とても良い
eq_mid               0.0091   0.471  ← まあまあ
eq_high              0.0126   0.906  ← 良い
eq_presence          0.0119   0.943  ← とても良い
transient_attack     0.0099   0.964  ← 素晴らしい！
transient_sustain    0.0111   0.710  ← 良い
time_stretch         0.0145   0.417  ← まあまあ
```

---

## 🖥️ 実際のコード例

### データセット作成

```python
# ガンガンのテンプレート
'ガンガン': [0.6, 0.5, 0.3, 0.5, 0.4, 0.2, -0.1, 0.8, 0.3, 0.0]

# バリエーションを作る
for sound_id in range(100):
    # 少しランダムに変化
    params = [0.6 + random()*0.1, 0.5 + random()*0.1, ...]

    # データを追加
    dataset.add('ガンガン', sound_id, params)
```

### 特徴量抽出

```python
# オノマトペを特徴量に変換
onomatopoeia = "ガンガン"

# 1. 音素列に変換
phonemes = ['g', 'a', 'N', 'g', 'a', 'N']

# 2. モーラ列に変換
moras = ['ga', 'N', 'ga', 'N']

# 3. 特徴量を計算
features = [
    len(moras),              # モーラ数 = 4
    count_consonants(...),   # 子音数 = 2
    count_vowels(...),       # 母音数 = 2
    ...                      # 残り35個
]  # 合計38個
```

### モデル定義

```python
import torch.nn as nn

class Onoma2DSPMLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(38, 32),   # 入力層 → 隠れ層
            nn.ReLU(),           # 活性化関数
            nn.Linear(32, 10),   # 隠れ層 → 出力層
            nn.Tanh()            # -1〜+1に制限
        )

    def forward(self, x):
        return self.net(x)
```

### 学習ループ

```python
# モデルとオプティマイザを作成
model = Onoma2DSPMLP()
optimizer = Adam(model.parameters(), lr=0.001)
criterion = MSELoss()

# 150エポック繰り返す
for epoch in range(150):
    # 全訓練データで学習
    for batch_x, batch_y in train_loader:
        # 予測
        pred = model(batch_x)

        # 誤差を計算
        loss = criterion(pred, batch_y)

        # 重みを更新
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # 検証データで評価
    val_loss = evaluate(model, val_loader)
    print(f"Epoch {epoch}: Loss={val_loss}")
```

### 推論

```python
# 学習済みモデルで予測
onomatopoeia = "ガンガン"

# 1. 特徴量抽出
features = extract_features(onomatopoeia)

# 2. モデルで予測
dsp_params = model(features)
# → [0.603, 0.494, 0.399, ...]

# 3. DSPパラメータにマッピング
gain_db = 12 * dsp_params[0]      # 7.23 dB
eq_sub_db = 12 * dsp_params[2]    # 4.79 dB
...
```

---

## 🎓 まとめ

### 学習プロセスの全体像

```
1. データ準備（1,300個）
   ↓
2. オノマトペ → 38次元の特徴量
   ↓
3. MLPモデル（38 → 32 → 10）
   ↓
4. 学習（150エポック）
   - 誤差を計算
   - 重みを調整
   - 繰り返す
   ↓
5. 評価（R² = 0.824）
   ↓
6. 推論（新しいオノマトペに適用）
```

### キーポイント

1. **データセット**: 1,300個のオノマトペとDSPパラメータのペア
2. **特徴量**: オノマトペを38個の数値で表現
3. **モデル**: 38 → 32 → 10 の3層ニューラルネットワーク
4. **学習**: 誤差を最小化するように重みを調整（150エポック）
5. **精度**: R² = 0.824（82.4%の精度）

### なぜうまくいくのか？

1. **音象徴の一貫性**: 「ガンガン」は力強い、「サラサラ」は軽やか、という人間共通の感覚
2. **音素の特徴**: `g`音は低音、`i`音は高音、という音響的特徴
3. **十分なデータ**: 1,300個のサンプルでパターンを学習
4. **適切なモデル**: MLPは非線形な関係を学習できる

### 実用的な成果

- **音量制御**: -78%〜+363%の範囲で調整
- **周波数特性**: 低音強調 vs 高音強調
- **音質の差別化**: ガンガン（力強い）vs フワフワ（柔らかい）

---

**作成日**: 2025年12月1日
**対象**: 機械学習初心者
**プロジェクト**: オノマトペからDSPパラメータを推論するMLPモデル
