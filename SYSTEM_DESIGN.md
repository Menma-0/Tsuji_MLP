# Onoma2DSP ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆæ›¸

å·®åˆ†ã‚ªãƒãƒãƒˆãƒšã«ã‚ˆã‚‹éŸ³å£°å¤‰æ›ã‚·ã‚¹ãƒ†ãƒ ã®æŠ€è¡“è©³ç´°

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 1.0
**æœ€çµ‚æ›´æ–°:** 2025-12-03

---

## ğŸ“‹ ç›®æ¬¡

1. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
2. [å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
3. [ã‚ªãƒãƒãƒˆãƒšç‰¹å¾´é‡æŠ½å‡ºã®è©³ç´°](#ã‚ªãƒãƒãƒˆãƒšç‰¹å¾´é‡æŠ½å‡ºã®è©³ç´°)
4. [å·®åˆ†ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°](#å·®åˆ†ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°)
5. [DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°](#dspãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°)
6. [Attentionæ©Ÿæ§‹](#attentionæ©Ÿæ§‹)
7. [å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ—ãƒ­ã‚»ã‚¹](#å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ—ãƒ­ã‚»ã‚¹)
8. [å®Ÿè£…ã®è©³ç´°](#å®Ÿè£…ã®è©³ç´°)

---

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### ã‚³ã‚¢ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯**å·®åˆ†ãƒ™ãƒ¼ã‚¹**ã®ã‚ªãƒãƒãƒˆãƒšéŸ³å£°å¤‰æ›ã‚’å®Ÿç¾ã—ã¾ã™ï¼š

```
å…¥åŠ›: source_onomatopoeiaï¼ˆç¾åœ¨ã®éŸ³ï¼‰+ target_onomatopoeiaï¼ˆç›®æ¨™ã®éŸ³ï¼‰
      â†“
ç‰¹å¾´é‡å·®åˆ†: Î”Ï† = Ï†(target) - Ï†(source)
      â†“
MLPãƒ¢ãƒ‡ãƒ«: Î”Ï† â†’ Î”DSP (10æ¬¡å…ƒ)
      â†“
å‡ºåŠ›: å®Ÿéš›ã®DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```

**é‡è¦ãªè¨­è¨ˆæ€æƒ³:**
- ã‚ªãƒãƒãƒˆãƒšè‡ªä½“ã‹ã‚‰**ç›´æ¥**DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’äºˆæ¸¬ã™ã‚‹ã®ã§ã¯ãªãã€**2ã¤ã®ã‚ªãƒãƒãƒˆãƒšã®å·®åˆ†**ã‹ã‚‰DSPå¤‰åŒ–ã‚’äºˆæ¸¬
- ã“ã‚Œã«ã‚ˆã‚Šã€ã€Œãƒãƒªãƒ³â†’ã‚´ãƒ­ã‚´ãƒ­ã€ã®ã‚ˆã†ãªç›¸å¯¾çš„ãªéŸ³è³ªå¤‰åŒ–ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å…¥åŠ›éŸ³å£°ã®ç‰¹æ€§ï¼ˆsourceï¼‰ã¨ç›®æ¨™ï¼ˆtargetï¼‰ã‚’ä¸¡æ–¹æŒ‡å®š

### ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´

1. **å·®åˆ†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: 2ã¤ã®ã‚ªãƒãƒãƒˆãƒšã®ç‰¹å¾´é‡å·®åˆ†ã‚’è¨ˆç®—
2. **è»½é‡MLP**: 38æ¬¡å…ƒå…¥åŠ› â†’ 32æ¬¡å…ƒéš ã‚Œå±¤ â†’ 10æ¬¡å…ƒå‡ºåŠ›
3. **Attentionæ©Ÿæ§‹**: ã‚½ãƒ¼ã‚¹ã‚ªãƒãƒãƒˆãƒšã«åŸºã¥ãé©å¿œçš„ãªè£œæ­£
4. **å±¥æ­´è¨˜éŒ²**: å…¨ã¦ã®å‡¦ç†ã‚’è‡ªå‹•è¨˜éŒ²

---

## å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```
[ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›]
    â”œâ”€ source_onomatopoeia: "ãƒãƒªãƒ³"
    â”œâ”€ target_onomatopoeia: "ã‚´ãƒ­ã‚´ãƒ­"
    â””â”€ input_audio: bell.wav
         â†“
[1. ã‚ªãƒãƒãƒˆãƒšå‰å‡¦ç†]
    â”œâ”€ ã‚«ã‚¿ã‚«ãƒŠ â†’ éŸ³ç´ åˆ— (KatakanaToPhoneme)
    â”‚   "ãƒãƒªãƒ³" â†’ ['ch', 'i', 'r', 'i', 'N']
    â”œâ”€ éŸ³ç´ åˆ— â†’ ãƒ¢ãƒ¼ãƒ©åˆ— (PhonemeToMora)
    â”‚   â†’ [('ch', 'i'), ('r', 'i'), ('N',)]
    â””â”€ ç‰¹å¾´é‡æŠ½å‡º (OnomatopoeiaFeatureExtractor)
        â†’ Ï†(source): 38æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«
        â†’ Ï†(target): 38æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«
         â†“
[2. å·®åˆ†è¨ˆç®—]
    Î”Ï† = Ï†(target) - Ï†(source)  # 38æ¬¡å…ƒ
         â†“
[3. æ¨™æº–åŒ–] (Optional)
    Î”Ï†_scaled = StandardScaler.transform(Î”Ï†)
         â†“
[4. MLPãƒ¢ãƒ‡ãƒ«æ¨è«–]
    Î”DSP_norm = MLP(Î”Ï†_scaled)  # 10æ¬¡å…ƒã€ç¯„å›²[-1, +1]
         â†“
[5. Amplification] (Optional)
    Î”DSP_norm = Î”DSP_norm Ã— amplification_factor
    ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0 = ç­‰å€ï¼‰
         â†“
[6. Attentionè£œæ­£] (Optional)
    attention = |create_dsp_template(source)|ã‚’æ­£è¦åŒ–
    Î”DSP_final = Î”DSP_norm Ã— (1.0 + lambda_att Ã— attention)
         â†“
[7. DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°]
    Î”DSP_final â†’ å®Ÿéš›ã®dBå€¤ã€å€ç‡ãªã©
    ä¾‹: gain_db = 24.0 Ã— Î”DSP_final[0]
         â†“
[8. éŸ³å£°å‡¦ç†]
    â”œâ”€ EQ (5ãƒãƒ³ãƒ‰)
    â”œâ”€ Compression
    â”œâ”€ Transient Shaping
    â”œâ”€ Time Stretch
    â””â”€ Gainèª¿æ•´
         â†“
[å‡ºåŠ›éŸ³å£°]
    output.wav
```

### ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹æˆ

```
src/
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ katakana_to_phoneme.py      # ã‚«ã‚¿ã‚«ãƒŠâ†’éŸ³ç´ å¤‰æ›
â”‚   â”œâ”€â”€ phoneme_to_mora.py          # éŸ³ç´ â†’ãƒ¢ãƒ¼ãƒ©å¤‰æ›
â”‚   â””â”€â”€ feature_extractor.py        # ç‰¹å¾´é‡æŠ½å‡ºï¼ˆ38æ¬¡å…ƒï¼‰
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mlp_model.py                # MLPãƒ¢ãƒ‡ãƒ«ï¼ˆå·®åˆ†â†’DSPï¼‰
â”œâ”€â”€ dsp/
â”‚   â””â”€â”€ dsp_engine.py               # éŸ³å£°å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ create_rwcp_dataset.py      # DSPãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
â”œâ”€â”€ onoma2dsp.py                     # ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€â”€ cli.py                           # CLIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â””â”€â”€ train_with_rwcp.py               # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

---

## ã‚ªãƒãƒãƒˆãƒšç‰¹å¾´é‡æŠ½å‡ºã®è©³ç´°

### 3.1 æ¦‚è¦

ã‚ªãƒãƒãƒˆãƒšæ–‡å­—åˆ—ã‹ã‚‰**38æ¬¡å…ƒã®éŸ³éŸ¿çš„ç‰¹å¾´é‡**ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

```python
"ãƒãƒªãƒ³"
  â†’ ['ch', 'i', 'r', 'i', 'N'] (éŸ³ç´ åˆ—)
  â†’ [('ch','i'), ('r','i'), ('N',)] (ãƒ¢ãƒ¼ãƒ©åˆ—)
  â†’ [3.0, 2.0, 2.0, ...] (38æ¬¡å…ƒç‰¹å¾´é‡)
```

### 3.2 38æ¬¡å…ƒç‰¹å¾´é‡ã®å†…è¨³

| ã‚°ãƒ«ãƒ¼ãƒ— | æ¬¡å…ƒæ•° | ç‰¹å¾´é‡ | èª¬æ˜ |
|---------|--------|--------|------|
| **A: å…¨ä½“æ§‹é€ ** | 6 | M, C_count, V_count, word_repeat_count, mora_repeat_chunk_count, mora_repeat_ratio | ãƒ¢ãƒ¼ãƒ©æ•°ã€å­éŸ³/æ¯éŸ³æ•°ã€ç¹°ã‚Šè¿”ã— |
| **B: é•·ã•ãƒ»ã‚¢ã‚¯ã‚»ãƒ³ãƒˆ** | 4 | Q_count, H_mora_count, H_ratio, ending_is_long | ä¿ƒéŸ³ã€é•·éŸ³ã®æƒ…å ± |
| **C: æ¯éŸ³ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ** | 5 | v_a, v_i, v_u, v_e, v_o | å„æ¯éŸ³ã®å‡ºç¾å›æ•° |
| **D: å­éŸ³ã‚«ãƒ†ã‚´ãƒª** | 6 | voiceless_plosive, voiced_plosive, voiceless_fric, voiced_fric, nasal, approximant | å­éŸ³ã®éŸ³éŸ»çš„ã‚«ãƒ†ã‚´ãƒª |
| **E: å­éŸ³æ¯”ç‡** | 3 | obstruent_ratio, voiced_cons_ratio, nasal_ratio | å­éŸ³ã®æ€§è³ªã®æ¯”ç‡ |
| **F: ä½ç½®æƒ…å ±** | 14 | èªé ­/èªæœ«ã®å­éŸ³ã‚«ãƒ†ã‚´ãƒªï¼ˆå„6æ¬¡å…ƒï¼‰ã€starts/ends_with_vowel | èªé ­ãƒ»èªæœ«ã®éŸ³éŸ»æƒ…å ± |

### 3.3 å„ã‚°ãƒ«ãƒ¼ãƒ—ã®è©³ç´°

#### ã‚°ãƒ«ãƒ¼ãƒ—A: å…¨ä½“æ§‹é€ ãƒ»ç¹°ã‚Šè¿”ã—ï¼ˆ6æ¬¡å…ƒï¼‰

```python
def _extract_structure_features(phonemes, moras):
    M = len(moras)  # ãƒ¢ãƒ¼ãƒ©æ•°

    # å­éŸ³ãƒ»æ¯éŸ³ã®ã‚«ã‚¦ãƒ³ãƒˆ
    C_count = count_consonants(phonemes)  # 'ch', 'r' ãªã©
    V_count = count_vowels(phonemes)      # 'a', 'i', 'u', 'e', 'o'

    # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³
    word_repeat_count = detect_word_repeat(moras)
    # ä¾‹: "ã‚´ãƒ­ã‚´ãƒ­" â†’ ['go', 'ro', 'go', 'ro'] â†’ 2å›ç¹°ã‚Šè¿”ã—

    mora_repeat_chunk_count = count_repeat_chunks(moras)
    # ä¾‹: "ã‚«ãƒƒã‚«ãƒƒ" â†’ ['ka', 'Q', 'ka', 'Q'] â†’ 2å¡Š

    mora_repeat_ratio = repeated_moras / M
    # ç¹°ã‚Šè¿”ã—ã¦ã„ã‚‹ãƒ¢ãƒ¼ãƒ©ã®å‰²åˆ

    return [M, C_count, V_count, word_repeat_count,
            mora_repeat_chunk_count, mora_repeat_ratio]
```

**éŸ³éŸ¿çš„è§£é‡ˆ:**
- `M`ï¼ˆãƒ¢ãƒ¼ãƒ©æ•°ï¼‰: éŸ³ã®é•·ã•ãƒ»æŒç¶šæ™‚é–“ã«å¯¾å¿œ
- `word_repeat_count`: å‘¨æœŸæ€§ãƒ»ãƒªã‚ºãƒ æ€§ï¼ˆã‚¬ãƒ³ã‚¬ãƒ³ = 2å›ï¼‰
- `mora_repeat_ratio`: ç¹°ã‚Šè¿”ã—ã®å¼·ã•ï¼ˆãƒªã‚ºãƒŸã‚«ãƒ«ã•ï¼‰

#### ã‚°ãƒ«ãƒ¼ãƒ—B: é•·ã•ãƒ»ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼ˆ4æ¬¡å…ƒï¼‰

```python
def _extract_length_features(phonemes, moras):
    Q_count = count_Q(phonemes)  # ä¿ƒéŸ³ã€Œãƒƒã€
    # ä¾‹: "ã‚«ãƒƒ" â†’ ['k', 'a', 'Q'] â†’ 1

    H_mora_count = count_long_vowels(moras)  # é•·éŸ³ã€Œãƒ¼ã€
    # ä¾‹: "ã‚­ãƒ¼ãƒ³" â†’ ['ki', 'H', 'N'] â†’ 1

    H_ratio = H_mora_count / M

    ending_is_long = 1.0 if moras[-1]ã«'H'å«ã‚€ else 0.0

    return [Q_count, H_mora_count, H_ratio, ending_is_long]
```

**éŸ³éŸ¿çš„è§£é‡ˆ:**
- `Q_count`: ã‚¢ã‚¿ãƒƒã‚¯ã®é‹­ã•ï¼ˆä¿ƒéŸ³ = çŸ­ã„ç„¡éŸ³ = é‹­ã„ã‚¢ã‚¿ãƒƒã‚¯ï¼‰
- `H_mora_count`: ã‚µã‚¹ãƒ†ã‚£ãƒ³ãƒ»æŒç¶šæ€§ï¼ˆé•·éŸ³ = ä¼¸ã³ã‚‹éŸ³ï¼‰
- `ending_is_long`: éŸ³ã®çµ‚ã‚ã‚Šæ–¹ï¼ˆæ¸›è¡°ç‰¹æ€§ï¼‰

#### ã‚°ãƒ«ãƒ¼ãƒ—C: æ¯éŸ³ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆ5æ¬¡å…ƒï¼‰

```python
def _extract_vowel_histogram(phonemes):
    # å„æ¯éŸ³ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    return [
        count('a'),  # "ã‚¢" - é–‹å£åº¦å¤§ã€æ˜ã‚‹ã„
        count('i'),  # "ã‚¤" - é«˜éŸ³ã€é‹­ã„
        count('u'),  # "ã‚¦" - ä¸¸ã¿ã€ã“ã‚‚ã£ãŸ
        count('e'),  # "ã‚¨" - ä¸­é–“
        count('o')   # "ã‚ª" - ä½éŸ³ã€æš—ã„
    ]
```

**éŸ³éŸ¿çš„è§£é‡ˆ:**
- æ¯éŸ³ã®ç¨®é¡ã¯**ãƒ•ã‚©ãƒ«ãƒãƒ³ãƒˆï¼ˆå…±é³´å‘¨æ³¢æ•°ï¼‰**ã«å¯¾å¿œ
- `i`ãŒå¤šã„ â†’ é«˜å‘¨æ³¢æˆåˆ†ãŒå¼·ã„ï¼ˆã‚­ãƒ©ã‚­ãƒ©ã€ãƒãƒªãƒ³ï¼‰
- `o`ãŒå¤šã„ â†’ ä½å‘¨æ³¢æˆåˆ†ãŒå¼·ã„ï¼ˆã‚´ãƒ­ã‚´ãƒ­ã€ãƒ‰ãƒ¼ãƒ³ï¼‰
- `u`ãŒå¤šã„ â†’ ä¸­åŸŸãŒå¼±ã„ã€ã“ã‚‚ã£ãŸéŸ³ï¼ˆãƒ–ãƒ¼ãƒ³ã€ã‚ºãƒ¼ãƒ³ï¼‰

#### ã‚°ãƒ«ãƒ¼ãƒ—D: å­éŸ³ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆ6æ¬¡å…ƒï¼‰

```python
# å­éŸ³ã®éŸ³éŸ»çš„åˆ†é¡
consonant_categories = {
    'voiceless_plosive': ['p', 't', 'k'],  # ç„¡å£°ç ´è£‚éŸ³
    'voiced_plosive': ['b', 'd', 'g'],     # æœ‰å£°ç ´è£‚éŸ³
    'voiceless_fric': ['s', 'sh', 'f', 'h'], # ç„¡å£°æ‘©æ“¦éŸ³
    'voiced_fric': ['z', 'j'],             # æœ‰å£°æ‘©æ“¦éŸ³
    'nasal': ['m', 'n', 'N'],              # é¼»éŸ³
    'approximant': ['r', 'w', 'y']         # æ¥è¿‘éŸ³
}

def _extract_consonant_category_histogram(phonemes):
    return [
        count('voiceless_plosive'),  # ã‚«ã€ã‚¿ã€ãƒ‘
        count('voiced_plosive'),     # ã‚¬ã€ãƒ€ã€ãƒ
        count('voiceless_fric'),     # ã‚µã€ã‚·ã€ãƒ
        count('voiced_fric'),        # ã‚¶ã€ã‚¸
        count('nasal'),              # ãƒ³ã€ãƒ 
        count('approximant')         # ãƒ©ã€ãƒ¯ã€ãƒ¤
    ]
```

**éŸ³éŸ¿çš„è§£é‡ˆ:**
- **ç„¡å£°ç ´è£‚éŸ³** (p, t, k): é‹­ã„ã‚¢ã‚¿ãƒƒã‚¯ã€é«˜å‘¨æ³¢ãƒã‚¤ã‚º
  - ä¾‹: "ã‚«ãƒƒ"ã€"ãƒ‘ãƒ³"
- **æœ‰å£°ç ´è£‚éŸ³** (b, d, g): ä½å‘¨æ³¢ã‚¨ãƒãƒ«ã‚®ãƒ¼ã€é‡ã¿
  - ä¾‹: "ã‚¬ãƒƒ"ã€"ãƒ‰ãƒ³"ã€"ã‚´ãƒ­"
- **ç„¡å£°æ‘©æ“¦éŸ³** (s, sh, f, h): ç¶™ç¶šçš„ãªé«˜å‘¨æ³¢ãƒã‚¤ã‚º
  - ä¾‹: "ã‚µãƒ©ã‚µãƒ©"ã€"ã‚·ãƒ£ãƒ¼"
- **æœ‰å£°æ‘©æ“¦éŸ³** (z, j): ç¶™ç¶šçš„ãªä¸­ã€œä½å‘¨æ³¢ãƒã‚¤ã‚º
  - ä¾‹: "ã‚¶ãƒ©ã‚¶ãƒ©"ã€"ã‚¸ãƒ¼"
- **é¼»éŸ³** (m, n, N): å…±é³´ã€ã“ã‚‚ã‚Šã€ä½å‘¨æ³¢
  - ä¾‹: "ãƒ³"ï¼ˆæ’¥éŸ³ï¼‰
- **æ¥è¿‘éŸ³** (r, w, y): æµéŸ³ã€æ»‘ã‚‰ã‹
  - ä¾‹: "ãƒªãƒ³"ã€"ãƒ¯ãƒ³"

#### ã‚°ãƒ«ãƒ¼ãƒ—E: å­éŸ³æ¯”ç‡ã®ã‚µãƒãƒªï¼ˆ3æ¬¡å…ƒï¼‰

```python
def _extract_consonant_ratio_summary(phonemes):
    C_count = total_consonants(phonemes)

    # é˜»å®³éŸ³ï¼ˆç ´è£‚éŸ³+æ‘©æ“¦éŸ³ï¼‰ã®å‰²åˆ
    obstruent_ratio = (plosive + fricative) / C_count

    # æœ‰å£°å­éŸ³ã®å‰²åˆ
    voiced_cons_ratio = (voiced_plosive + voiced_fric) / C_count

    # é¼»éŸ³ã®å‰²åˆ
    nasal_ratio = nasal / C_count

    return [obstruent_ratio, voiced_cons_ratio, nasal_ratio]
```

**éŸ³éŸ¿çš„è§£é‡ˆ:**
- `obstruent_ratio`ï¼ˆé˜»å®³éŸ³æ¯”ç‡ï¼‰: ãƒã‚¤ã‚¸ãƒ¼ã•ã€ç²—ã•
  - é«˜ã„ â†’ æ˜ç­ã€ãã£ãã‚Šï¼ˆã‚«ã‚­ã‚¯ã‚±ã‚³ã€ã‚µã‚·ã‚¹ã‚»ã‚½ï¼‰
- `voiced_cons_ratio`ï¼ˆæœ‰å£°æ¯”ç‡ï¼‰: ä½éŸ³æˆåˆ†ã®å¼·ã•
  - é«˜ã„ â†’ é‡åšã€æ¿ã‚Šï¼ˆã‚¬ã‚®ã‚°ã‚²ã‚´ã€ã‚¶ã‚¸ã‚ºã‚¼ã‚¾ï¼‰
- `nasal_ratio`ï¼ˆé¼»éŸ³æ¯”ç‡ï¼‰: å…±é³´ã€ã“ã‚‚ã‚Š
  - é«˜ã„ â†’ ä¸¸ã¿ã€æŸ”ã‚‰ã‹ã•

#### ã‚°ãƒ«ãƒ¼ãƒ—F: ä½ç½®æƒ…å ±ï¼ˆ14æ¬¡å…ƒï¼‰

```python
def _extract_position_features(moras):
    # èªé ­ã®å­éŸ³ã‚«ãƒ†ã‚´ãƒªï¼ˆ6æ¬¡å…ƒãƒ¯ãƒ³ãƒ›ãƒƒãƒˆï¼‰
    first_consonant_category = detect_first_consonant(moras[0])
    first_onehot = one_hot_encode(first_consonant_category, 6)

    # èªæœ«ã®å­éŸ³ã‚«ãƒ†ã‚´ãƒªï¼ˆ6æ¬¡å…ƒãƒ¯ãƒ³ãƒ›ãƒƒãƒˆï¼‰
    last_consonant_category = detect_last_consonant(moras[-1])
    last_onehot = one_hot_encode(last_consonant_category, 6)

    # èªé ­ãƒ»èªæœ«ãŒæ¯éŸ³ã§å§‹ã¾ã‚‹/çµ‚ã‚ã‚‹ã‹
    starts_with_vowel = 1.0 if moras[0][0] in vowels else 0.0
    ends_with_vowel = 1.0 if moras[-1][-1] in vowels else 0.0

    return first_onehot + last_onehot + [starts_with_vowel, ends_with_vowel]
```

**éŸ³éŸ¿çš„è§£é‡ˆ:**
- **èªé ­ã®å­éŸ³**: éŸ³ã®ç«‹ã¡ä¸ŠãŒã‚Šï¼ˆã‚¢ã‚¿ãƒƒã‚¯ï¼‰ã®æ€§è³ª
  - "ã‚«ãƒ¼ãƒ³" vs "ã‚¬ãƒ¼ãƒ³" â†’ ã‚¢ã‚¿ãƒƒã‚¯ã®é‹­ã•ãŒç•°ãªã‚‹
- **èªæœ«ã®å­éŸ³**: éŸ³ã®çµ‚ã‚ã‚Šæ–¹ï¼ˆãƒªãƒªãƒ¼ã‚¹ã€æ¸›è¡°ï¼‰
  - "ã‚«ãƒ³" vs "ã‚«ãƒ¼" â†’ çµ‚ã‚ã‚Šæ–¹ãŒç•°ãªã‚‹
- **æ¯éŸ³å§‹ã¾ã‚Š/çµ‚ã‚ã‚Š**: æŸ”ã‚‰ã‹ã• vs æ˜ç­ã•

### 3.4 å®Ÿè£…ä¾‹

```python
# "ã‚¬ãƒ³ã‚¬ãƒ³" ã®ç‰¹å¾´é‡æŠ½å‡ºä¾‹
phonemes = ['g', 'a', 'N', 'g', 'a', 'N']
moras = [('g', 'a'), ('N',), ('g', 'a'), ('N',)]

features = [
    # A: å…¨ä½“æ§‹é€ ï¼ˆ6æ¬¡å…ƒï¼‰
    4.0,    # M = 4ãƒ¢ãƒ¼ãƒ©
    2.0,    # C_count = 2å­éŸ³ï¼ˆg Ã— 2ï¼‰
    2.0,    # V_count = 2æ¯éŸ³ï¼ˆa Ã— 2ï¼‰
    2.0,    # word_repeat_count = 2å›ï¼ˆ"ã‚¬ãƒ³" ãŒ2å›ï¼‰
    0.0,    # mora_repeat_chunk_count = 0
    0.0,    # mora_repeat_ratio = 0

    # B: é•·ã•ï¼ˆ4æ¬¡å…ƒï¼‰
    0.0,    # Q_count = 0ï¼ˆä¿ƒéŸ³ãªã—ï¼‰
    0.0,    # H_mora_count = 0ï¼ˆé•·éŸ³ãªã—ï¼‰
    0.0,    # H_ratio = 0
    0.0,    # ending_is_long = 0

    # C: æ¯éŸ³ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼ˆ5æ¬¡å…ƒï¼‰
    2.0,    # v_a_count = 2
    0.0,    # v_i_count = 0
    0.0,    # v_u_count = 0
    0.0,    # v_e_count = 0
    0.0,    # v_o_count = 0

    # D: å­éŸ³ã‚«ãƒ†ã‚´ãƒªï¼ˆ6æ¬¡å…ƒï¼‰
    0.0,    # voiceless_plosive = 0
    2.0,    # voiced_plosive = 2ï¼ˆg Ã— 2ï¼‰
    0.0,    # voiceless_fric = 0
    0.0,    # voiced_fric = 0
    2.0,    # nasal = 2ï¼ˆN Ã— 2ï¼‰
    0.0,    # approximant = 0

    # E: å­éŸ³æ¯”ç‡ï¼ˆ3æ¬¡å…ƒï¼‰
    0.5,    # obstruent_ratio = 2/4ï¼ˆgãŒç ´è£‚éŸ³ï¼‰
    0.5,    # voiced_cons_ratio = 2/4ï¼ˆgãŒæœ‰å£°ï¼‰
    0.5,    # nasal_ratio = 2/4ï¼ˆNãŒé¼»éŸ³ï¼‰

    # F: ä½ç½®æƒ…å ±ï¼ˆ14æ¬¡å…ƒï¼‰
    0.0, 1.0, 0.0, 0.0, 0.0, 0.0,  # èªé ­ = voiced_plosive
    0.0, 0.0, 0.0, 0.0, 1.0, 0.0,  # èªæœ« = nasal
    0.0,    # starts_with_vowel = 0
    0.0,    # ends_with_vowel = 0
]
```

### 3.5 éŸ³éŸ¿çš„è§£é‡ˆã®å¯¾å¿œè¡¨

| ã‚ªãƒãƒãƒˆãƒšã®æ€§è³ª | å¯¾å¿œã™ã‚‹ç‰¹å¾´é‡ | DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¸ã®å½±éŸ¿ |
|--------------|-------------|-------------------|
| é«˜éŸ³ãƒ»é‹­ã„ | `v_i`å¤šã„ã€`voiceless_plosive`å¤šã„ | `eq_high`, `eq_presence` å¢—åŠ  |
| ä½éŸ³ãƒ»é‡ã„ | `v_o`/`v_u`å¤šã„ã€`voiced_plosive`å¤šã„ | `eq_sub`, `eq_low` å¢—åŠ  |
| ç¹°ã‚Šè¿”ã— | `word_repeat_count`é«˜ã„ | `compression`, `transient_attack` |
| é•·éŸ³ãƒ»æŒç¶š | `H_mora_count`é«˜ã„ | `transient_sustain`, `time_stretch` å¢—åŠ  |
| ä¿ƒéŸ³ãƒ»é‹­ã„ | `Q_count`é«˜ã„ | `transient_attack` å¢—åŠ  |
| æ¿éŸ³ãƒ»é‡åš | `voiced_cons_ratio`é«˜ã„ | `eq_sub`, `eq_low` å¢—åŠ ã€`gain` å¢—åŠ  |
| æ‘©æ“¦éŸ³ãƒ»ãƒã‚¤ã‚¸ãƒ¼ | `voiceless_fric`/`voiced_fric`å¤šã„ | `eq_high`, `eq_presence` |

---

## å·®åˆ†ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°

### 4.1 ãªãœå·®åˆ†ãƒ¢ãƒ‡ãƒ«ã‹ï¼Ÿ

å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆã‚ªãƒãƒãƒˆãƒš â†’ DSPï¼‰ã§ã¯ãªãã€**å·®åˆ†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**ã‚’æ¡ç”¨ï¼š

```python
# âŒ å¾“æ¥: çµ¶å¯¾çš„ãªãƒãƒƒãƒ”ãƒ³ã‚°
"ã‚´ãƒ­ã‚´ãƒ­" â†’ DSP parameters

# âœ… æœ¬ã‚·ã‚¹ãƒ†ãƒ : ç›¸å¯¾çš„ãªãƒãƒƒãƒ”ãƒ³ã‚°
("ãƒãƒªãƒ³" - "ã‚´ãƒ­ã‚´ãƒ­") â†’ Î”DSP parameters
```

**åˆ©ç‚¹:**
1. **ç›¸å¯¾çš„ãªéŸ³è³ªå¤‰åŒ–**ã‚’ç›´æ¥ãƒ¢ãƒ‡ãƒ«åŒ–
2. **å…¥åŠ›éŸ³å£°ã®ç‰¹æ€§**ï¼ˆsourceï¼‰ã‚’è€ƒæ…®ã§ãã‚‹
3. ã‚ˆã‚Š**ç›´æ„Ÿçš„ãªæ“ä½œ**ï¼ˆ"ä»Šãƒãƒªãƒ³ãªã‚‰ã€ã‚´ãƒ­ã‚´ãƒ­ã«ã™ã‚‹ã«ã¯..."ï¼‰

### 4.2 å·®åˆ†è¨ˆç®—

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: å„ã‚ªãƒãƒãƒˆãƒšã‹ã‚‰ç‰¹å¾´é‡æŠ½å‡º
Ï†_source = extract_features("ãƒãƒªãƒ³")  # 38æ¬¡å…ƒ
Ï†_target = extract_features("ã‚´ãƒ­ã‚´ãƒ­")  # 38æ¬¡å…ƒ

# ã‚¹ãƒ†ãƒƒãƒ—2: å·®åˆ†è¨ˆç®—
Î”Ï† = Ï†_target - Ï†_source  # 38æ¬¡å…ƒ

# ä¾‹:
# Ï†_source[0] = 3.0 (ãƒ¢ãƒ¼ãƒ©æ•°: "ãƒãƒªãƒ³" = 3ãƒ¢ãƒ¼ãƒ©)
# Ï†_target[0] = 4.0 (ãƒ¢ãƒ¼ãƒ©æ•°: "ã‚´ãƒ­ã‚´ãƒ­" = 4ãƒ¢ãƒ¼ãƒ©)
# Î”Ï†[0] = 4.0 - 3.0 = 1.0 (ãƒ¢ãƒ¼ãƒ©ãŒ1ã¤å¢—åŠ )
```

**å·®åˆ†ã®æ„å‘³:**
- `Î”Ï†[0] > 0`: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æ–¹ãŒãƒ¢ãƒ¼ãƒ©æ•°ãŒå¤šã„ â†’ éŸ³ãŒé•·ããªã‚‹
- `Î”Ï†[voiced_plosive] > 0`: æœ‰å£°ç ´è£‚éŸ³ãŒå¢—ãˆã‚‹ â†’ ä½éŸ³ãŒå¢—ãˆã‚‹
- `Î”Ï†[v_i] < 0`: 'i'æ¯éŸ³ãŒæ¸›ã‚‹ â†’ é«˜éŸ³æˆåˆ†ãŒæ¸›ã‚‹

### 4.3 MLPãƒ¢ãƒ‡ãƒ«æ§‹é€ 

```python
class Onoma2DSPMLP(nn.Module):
    def __init__(self, d_in=38, d_out=10, hidden_dim=32, use_tanh=True):
        super().__init__()

        self.net = nn.Sequential(
            nn.Linear(d_in, hidden_dim),   # 38 â†’ 32
            nn.ReLU(),
            nn.Linear(hidden_dim, d_out),  # 32 â†’ 10
            nn.Tanh()                       # å‡ºåŠ›ã‚’[-1, +1]ã«åˆ¶é™
        )
```

**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©³ç´°:**

```
å…¥åŠ›å±¤: 38æ¬¡å…ƒï¼ˆç‰¹å¾´é‡å·®åˆ† Î”Ï†ï¼‰
  â†“
å…¨çµåˆå±¤: 38 â†’ 32
  â†“
ReLUæ´»æ€§åŒ–
  â†“
å…¨çµåˆå±¤: 32 â†’ 10
  â†“
Tanhæ´»æ€§åŒ–ï¼ˆå‡ºåŠ›ã‚’-1ã€œ+1ã«åˆ¶é™ï¼‰
  â†“
å‡ºåŠ›å±¤: 10æ¬¡å…ƒï¼ˆæ­£è¦åŒ–ã•ã‚ŒãŸÎ”DSPï¼‰
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:**
- ç¬¬1å±¤: 38 Ã— 32 + 32 = 1,248
- ç¬¬2å±¤: 32 Ã— 10 + 10 = 330
- **åˆè¨ˆ: 1,578ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**

**è»½é‡ãªç†ç”±:**
- è¤‡é›‘ãªéç·šå½¢å¤‰æ›ã¯ä¸è¦ï¼ˆéŸ³éŸ»â†’éŸ³éŸ¿ã¯æ¯”è¼ƒçš„ç›´æ¥çš„ï¼‰
- éå­¦ç¿’ã‚’é˜²ããŸã‚å°è¦æ¨¡ã«
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã®ãŸã‚é«˜é€Ÿã«

### 4.4 å‡ºåŠ›ï¼ˆÎ”DSPï¼‰ã®10æ¬¡å…ƒ

```python
Î”DSP = [
    Î”gain,           # [0] ã‚²ã‚¤ãƒ³å¤‰åŒ–
    Î”compression,    # [1] åœ§ç¸®å¤‰åŒ–
    Î”eq_sub,         # [2] 80Hz EQå¤‰åŒ–
    Î”eq_low,         # [3] 250Hz EQå¤‰åŒ–
    Î”eq_mid,         # [4] 1kHz EQå¤‰åŒ–
    Î”eq_high,        # [5] 4kHz EQå¤‰åŒ–
    Î”eq_presence,    # [6] 10kHz EQå¤‰åŒ–
    Î”transient_attack,  # [7] ã‚¢ã‚¿ãƒƒã‚¯å¤‰åŒ–
    Î”transient_sustain, # [8] ã‚µã‚¹ãƒ†ã‚£ãƒ³å¤‰åŒ–
    Î”time_stretch    # [9] æ™‚é–“ä¼¸ç¸®å¤‰åŒ–
]
```

**å„æ¬¡å…ƒã®ç¯„å›²ã¨æ„å‘³:**

| æ¬¡å…ƒ | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ç¯„å›²ï¼ˆæ­£è¦åŒ–ï¼‰ | å®Ÿéš›ã®ç¯„å›² | éŸ³éŸ¿åŠ¹æœ |
|-----|-----------|------------|-----------|---------|
| 0 | gain | [-1, +1] | [-24dB, +24dB] | éŸ³é‡å¤‰åŒ– |
| 1 | compression | [-1, +1] | [-2.0, +2.0] | ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹åœ§ç¸® |
| 2 | eq_sub | [-1, +1] | [-24dB, +24dB] | è¶…ä½åŸŸï¼ˆ80Hzï¼‰ |
| 3 | eq_low | [-1, +1] | [-24dB, +24dB] | ä½åŸŸï¼ˆ250Hzï¼‰ |
| 4 | eq_mid | [-1, +1] | [-24dB, +24dB] | ä¸­åŸŸï¼ˆ1kHzï¼‰ |
| 5 | eq_high | [-1, +1] | [-24dB, +24dB] | é«˜åŸŸï¼ˆ4kHzï¼‰ |
| 6 | eq_presence | [-1, +1] | [-24dB, +24dB] | è¶…é«˜åŸŸï¼ˆ10kHzï¼‰ |
| 7 | transient_attack | [-1, +1] | [-2.0, +2.0] | ã‚¢ã‚¿ãƒƒã‚¯ã®é‹­ã• |
| 8 | transient_sustain | [-1, +1] | [-2.0, +2.0] | ã‚µã‚¹ãƒ†ã‚£ãƒ³ã®é•·ã• |
| 9 | time_stretch | [-1, +1] | [0.25x, 2.0x] | å†ç”Ÿé€Ÿåº¦ |

### 4.5 å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹

```python
# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X = []  # ç‰¹å¾´é‡å·®åˆ†ã®ãƒªã‚¹ãƒˆ
y = []  # DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

for sample in dataset:
    # å„ã‚µãƒ³ãƒ—ãƒ«ã¯ (onomatopoeia, audio_file, dsp_params) ã®ãƒšã‚¢
    Ï† = extract_features(onomatopoeia)
    X.append(Ï†)
    y.append(normalize_dsp_params(dsp_params))

# å­¦ç¿’
model = Onoma2DSPMLP(d_in=38, d_out=10, hidden_dim=32)
optimizer = Adam(model.parameters(), lr=0.001)
criterion = MSELoss()

for epoch in range(200):
    for Î”Ï†_batch, Î”DSP_batch in dataloader:
        # Forward
        Î”DSP_pred = model(Î”Ï†_batch)
        loss = criterion(Î”DSP_pred, Î”DSP_batch)

        # Backward
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

**æå¤±é–¢æ•°: MSE (Mean Squared Error)**

```python
loss = MSE(Î”DSP_pred, Î”DSP_true)
     = (1/10) Î£(Î”DSP_pred[i] - Î”DSP_true[i])Â²
```

**è©•ä¾¡æŒ‡æ¨™:**
1. **MSE**: äºˆæ¸¬èª¤å·®ã®å¤§ãã•
2. **RÂ² Score**: èª¬æ˜åŠ›ï¼ˆ1.0ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰
3. **ç¬¦å·æ­£è§£ç‡**: å¤‰åŒ–ã®æ–¹å‘ãŒæ­£ã—ã„ã‹ï¼ˆå¢—åŠ /æ¸›å°‘ï¼‰

### 4.6 æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹

```python
# æ¨è«–æ™‚
def predict(source_onoma, target_onoma):
    # 1. ç‰¹å¾´é‡æŠ½å‡º
    Ï†_source = extract_features(source_onoma)
    Ï†_target = extract_features(target_onoma)

    # 2. å·®åˆ†è¨ˆç®—
    Î”Ï† = Ï†_target - Ï†_source

    # 3. æ¨™æº–åŒ–ï¼ˆå­¦ç¿’æ™‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ç”¨ï¼‰
    Î”Ï†_scaled = scaler.transform(Î”Ï†.reshape(1, -1))

    # 4. ãƒ¢ãƒ‡ãƒ«æ¨è«–
    with torch.no_grad():
        Î”Ï†_tensor = torch.FloatTensor(Î”Ï†_scaled)
        Î”DSP_norm = model(Î”Ï†_tensor).numpy()[0]
    # Î”DSP_norm ã®ç¯„å›²: [-1, +1]

    # 5. Amplificationï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    Î”DSP_norm = np.clip(
        Î”DSP_norm * amplification_factor,
        -1.0, 1.0
    )

    # 6. Attentionè£œæ­£ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if lambda_att > 0:
        attention = compute_attention(source_onoma)
        Î”DSP_norm = Î”DSP_norm * (1.0 + lambda_att * attention)
        Î”DSP_norm = np.clip(Î”DSP_norm, -1.0, 1.0)

    # 7. å®Ÿéš›ã®DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    dsp_params = map_to_real_values(Î”DSP_norm)

    return dsp_params
```

---

## DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°

### 5.1 ãƒãƒƒãƒ”ãƒ³ã‚°é–¢æ•°

æ­£è¦åŒ–å€¤[-1, +1]ã‚’å®Ÿéš›ã®DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›ï¼š

```python
def map_parameters(normalized_params):
    """
    normalized_params: 10æ¬¡å…ƒã€ç¯„å›²[-1, +1]
    æˆ»ã‚Šå€¤: å®Ÿéš›ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¾æ›¸
    """

    # Gain: -24dB ã€œ +24dB
    gain_db = 24.0 * normalized_params[0]

    # Compression: -2.0 ã€œ +2.0
    compression = 2.0 * normalized_params[1]

    # EQ (5ãƒãƒ³ãƒ‰): -24dB ã€œ +24dB
    eq_sub_db = 24.0 * normalized_params[2]
    eq_low_db = 24.0 * normalized_params[3]
    eq_mid_db = 24.0 * normalized_params[4]
    eq_high_db = 24.0 * normalized_params[5]
    eq_presence_db = 24.0 * normalized_params[6]

    # Transient: -2.0 ã€œ +2.0
    transient_attack = 2.0 * normalized_params[7]
    transient_sustain = 2.0 * normalized_params[8]

    # Time Stretch: 0.25å€ ã€œ 2.0å€
    # -1 â†’ 0.25, 0 â†’ 1.0, +1 â†’ 2.0
    time_stretch_ratio = 1.0 + 0.75 * normalized_params[9]

    return {
        'gain_db': gain_db,
        'compression': compression,
        'eq_sub_db': eq_sub_db,
        'eq_low_db': eq_low_db,
        'eq_mid_db': eq_mid_db,
        'eq_high_db': eq_high_db,
        'eq_presence_db': eq_presence_db,
        'transient_attack': transient_attack,
        'transient_sustain': transient_sustain,
        'time_stretch_ratio': time_stretch_ratio
    }
```

### 5.2 å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®éŸ³éŸ¿åŠ¹æœ

#### EQãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```
å‘¨æ³¢æ•°å¸¯åŸŸã®é…ç½®:

  eq_sub (80Hz)      è¶…ä½åŸŸ  ã€Œã‚ºãƒ¼ãƒ³ã€ã€Œã‚´ãƒ¼ãƒ³ã€ã®è¿«åŠ›
    â†“
  eq_low (250Hz)     ä½åŸŸ    ã€Œãƒ‰ãƒ³ã€ã€Œã‚´ãƒ­ã€ã®é‡åšæ„Ÿ
    â†“
  eq_mid (1kHz)      ä¸­åŸŸ    éŸ³ã®æ˜ç­åº¦ã€å­˜åœ¨æ„Ÿ
    â†“
  eq_high (4kHz)     é«˜åŸŸ    ã€Œã‚«ãƒ³ã€ã€Œã‚­ãƒ³ã€ã®æ˜ã‚‹ã•
    â†“
  eq_presence (10kHz) è¶…é«˜åŸŸ  ã€Œãƒãƒªãƒ³ã€ã€Œã‚­ãƒ©ã‚­ãƒ©ã€ã®ç…Œã‚ã
```

**EQã®åŠ¹æœä¾‹:**

```python
# "ãƒãƒªãƒ³" â†’ "ã‚´ãƒ­ã‚´ãƒ­" ã®å ´åˆ
eq_high_db = -18.0      # é«˜éŸ³ã‚’18dBæ¸›è¡°ï¼ˆãƒãƒªãƒ³ã®ç‰¹å¾´ã‚’æŠ‘ãˆã‚‹ï¼‰
eq_presence_db = -20.0  # è¶…é«˜åŸŸã‚’20dBæ¸›è¡°
eq_sub_db = +15.0       # è¶…ä½åŸŸã‚’15dBå¢—å¹…ï¼ˆã‚´ãƒ­ã‚´ãƒ­ã®ç‰¹å¾´ï¼‰
eq_low_db = +18.0       # ä½åŸŸã‚’18dBå¢—å¹…
```

#### Transient Shaping

```python
# transient_attack: -2.0 ã€œ +2.0
# è² ã®å€¤: ã‚¢ã‚¿ãƒƒã‚¯ã‚’éˆã‚‰ã›ã‚‹ï¼ˆæŸ”ã‚‰ã‹ãï¼‰
# æ­£ã®å€¤: ã‚¢ã‚¿ãƒƒã‚¯ã‚’é‹­ãã™ã‚‹ï¼ˆæ˜ç­ã«ï¼‰

# transient_sustain: -2.0 ã€œ +2.0
# è² ã®å€¤: ã‚µã‚¹ãƒ†ã‚£ãƒ³ã‚’çŸ­ãï¼ˆæ­¯åˆ‡ã‚Œè‰¯ãï¼‰
# æ­£ã®å€¤: ã‚µã‚¹ãƒ†ã‚£ãƒ³ã‚’é•·ãï¼ˆä½™éŸ»ã‚’ä¼¸ã°ã™ï¼‰
```

**åŠ¹æœä¾‹:**

```python
# "ã‚«ãƒƒ" â†’ "ã‚¬ãƒƒ" ã®å ´åˆ
transient_attack = -0.8   # ã‚¢ã‚¿ãƒƒã‚¯ã‚’ã‚„ã‚„éˆã‚‰ã›ã‚‹
transient_sustain = +0.3  # ã‚µã‚¹ãƒ†ã‚£ãƒ³ã‚’ã‚„ã‚„ä¼¸ã°ã™

# "ãƒãƒ³" â†’ "ãƒãƒ³" ã®å ´åˆ
transient_attack = +1.2   # ã‚¢ã‚¿ãƒƒã‚¯ã‚’é‹­ãã™ã‚‹
```

---

## Attentionæ©Ÿæ§‹

### 6.1 æ¦‚å¿µ

**å•é¡Œæ„è­˜:**
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ"ãƒãƒªãƒ³"ã¨è¨€ã†ã¨ãã€**é«˜éŸ³åŸŸã«æ³¨ç›®ã—ã¦ã„ã‚‹**
- "ã‚´ãƒ­ã‚´ãƒ­"ã¨è¨€ã†ã¨ãã€**ä½éŸ³åŸŸã«æ³¨ç›®ã—ã¦ã„ã‚‹**
- ã“ã®ã€Œæ³¨ç›®ã€æƒ…å ±ã‚’æ´»ç”¨ã—ã¦DSPå¤‰åŒ–ã‚’è£œæ­£

**Attentionæ©Ÿæ§‹ã®å½¹å‰²:**
```
ã‚½ãƒ¼ã‚¹ã‚ªãƒãƒãƒˆãƒš â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ³¨ç›®é ˜åŸŸã‚’æ¨å®š
                 â†“
        ãã®é ˜åŸŸã®å¤‰åŒ–ã‚’å¼·èª¿
```

### 6.2 å®Ÿè£…

```python
def apply_attention_correction(normalized_params, source_onoma, lambda_att):
    """
    Attentionè£œæ­£ã‚’é©ç”¨

    Args:
        normalized_params: MLPã®å‡ºåŠ›ï¼ˆ10æ¬¡å…ƒã€-1ã€œ+1ï¼‰
        source_onoma: ã‚½ãƒ¼ã‚¹ã‚ªãƒãƒãƒˆãƒšï¼ˆä¾‹: "ãƒãƒªãƒ³"ï¼‰
        lambda_att: Attentionå¼·åº¦ï¼ˆ0.0ã€œ1.0ï¼‰

    Returns:
        è£œæ­£å¾Œã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    """

    # 1. ã‚½ãƒ¼ã‚¹ã‚ªãƒãƒãƒˆãƒšã®DSPãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ
    template = create_dsp_template(source_onoma)
    # template: [gain, comp, eq_sub, eq_low, eq_mid,
    #            eq_high, eq_pres, atk, sus, stretch]

    # 2. çµ¶å¯¾å€¤ã‚’å–ã£ã¦æ³¨ç›®åº¦ãƒ™ã‚¯ãƒˆãƒ«ã«ã™ã‚‹
    attention = np.abs(template)
    # ç†ç”±: æ­£è² ã®ç¬¦å·ã¯é–¢ä¿‚ãªãã€ã€Œãã®æ¬¡å…ƒãŒé‡è¦ã‹ã€ã‚’çŸ¥ã‚ŠãŸã„

    # 3. 0-1ã«æ­£è¦åŒ–
    attention = attention / np.max(attention) if np.max(attention) > 0 else attention

    # 4. è£œæ­£å¼ã‚’é©ç”¨
    corrected = normalized_params * (1.0 + lambda_att * attention)

    # 5. ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
    corrected = np.clip(corrected, -1.0, 1.0)

    return corrected
```

### 6.3 create_dsp_template ã®è©³ç´°

```python
def create_dsp_template(onomatopoeia):
    """
    ã‚ªãƒãƒãƒˆãƒšã‹ã‚‰ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªDSPãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ

    Returns:
        10æ¬¡å…ƒã®DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ­£è¦åŒ–å€¤ -1ã€œ+1ï¼‰
    """
    # éŸ³ç´ ãƒ»ãƒ¢ãƒ¼ãƒ©ã«å¤‰æ›
    phonemes = katakana_to_phoneme(onomatopoeia)
    moras = phoneme_to_mora(phonemes)

    # åˆæœŸå€¤
    params = [0.0] * 10

    # æ¿éŸ³ã‚«ã‚¦ãƒ³ãƒˆï¼ˆg, d, z, bï¼‰
    voiced_count = count_voiced_consonants(phonemes)

    # é«˜éŸ³ç³»å­éŸ³ï¼ˆk, p, t, s, sh, ch, tsï¼‰
    high_consonants = count_high_consonants(phonemes)

    # ä¿ƒéŸ³ãƒ»é•·éŸ³
    sokuon_count = count_Q(phonemes)
    choon_count = count_H(phonemes)

    # === ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š ===

    # 1. Gain: æ¿éŸ³ãŒå¤šã„ â†’ å¤§éŸ³é‡
    if voiced_count >= 2:
        params[0] = 0.3 + 0.2 * min(voiced_count, 4)
    elif high_consonants >= 1:
        params[0] = -0.2 - 0.1 * min(high_consonants, 3)

    # 2. Compression
    if voiced_count >= 2:
        params[1] = 0.3 + 0.1 * min(voiced_count, 4)

    # 3. EQ Subï¼ˆè¶…ä½åŸŸï¼‰
    if voiced_count >= 2:
        params[2] = 0.4 + 0.2 * min(voiced_count, 4)  # æ¿éŸ³ â†’ ä½éŸ³å¼·åŒ–
    elif high_consonants >= 1:
        params[2] = -0.3 - 0.1 * min(high_consonants, 3)  # é«˜éŸ³ç³» â†’ ä½éŸ³ã‚«ãƒƒãƒˆ

    # 4. EQ Lowï¼ˆä½åŸŸï¼‰
    if voiced_count >= 1:
        params[3] = 0.3 + 0.2 * min(voiced_count, 4)
    elif high_consonants >= 1:
        params[3] = -0.2 - 0.1 * min(high_consonants, 3)

    # 5. EQ Midï¼ˆä¸­åŸŸï¼‰
    params[4] = 0.0  # ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«

    # 6. EQ Highï¼ˆé«˜åŸŸï¼‰
    if high_consonants >= 1:
        params[5] = 0.4 + 0.2 * min(high_consonants, 4)  # é«˜éŸ³ç³» â†’ é«˜éŸ³å¼·èª¿
    elif voiced_count >= 2:
        params[5] = -0.2 - 0.1 * min(voiced_count, 3)  # æ¿éŸ³ â†’ é«˜éŸ³ã‚«ãƒƒãƒˆ

    # 7. EQ Presenceï¼ˆè¶…é«˜åŸŸï¼‰
    if high_consonants >= 1:
        params[6] = 0.5 + 0.2 * min(high_consonants, 4)
    elif voiced_count >= 2:
        params[6] = -0.2 - 0.1 * min(voiced_count, 3)

    # 8. Transient Attack
    if sokuon_count > 0:
        params[7] = 0.7  # ä¿ƒéŸ³ â†’ é‹­ã„ã‚¢ã‚¿ãƒƒã‚¯
    elif choon_count > 1:
        params[7] = -0.4  # é•·éŸ³ â†’ æŸ”ã‚‰ã‹ã„ã‚¢ã‚¿ãƒƒã‚¯

    # 9. Transient Sustain
    if choon_count > 1:
        params[8] = 0.6  # é•·éŸ³ â†’ é•·ã„ã‚µã‚¹ãƒ†ã‚£ãƒ³
    elif sokuon_count > 0:
        params[8] = -0.3  # ä¿ƒéŸ³ â†’ çŸ­ã„

    # 10. Time Stretch
    if choon_count > 2:
        params[9] = 0.3  # é•·éŸ³å¤šã„ â†’ ã‚„ã‚„ä¼¸ã°ã™
    elif sokuon_count > 1:
        params[9] = -0.2  # ä¿ƒéŸ³å¤šã„ â†’ ã‚„ã‚„çŸ­ã

    return params
```

### 6.4 Attentionã®åŠ¹æœ

**ä¾‹: "ãƒãƒªãƒ³" â†’ "ã‚´ãƒ­ã‚´ãƒ­"**

```python
# 1. ã‚½ãƒ¼ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
template_chirin = create_dsp_template("ãƒãƒªãƒ³")
# = [-0.3, 0, -0.4, -0.3, 0, 0.6, 0.7, 0, 0, 0]
#     â†‘                     â†‘    â†‘
#   gainä½ã‚            é«˜éŸ³ç³»ãŒå¼·ã„

# 2. æ³¨ç›®åº¦ãƒ™ã‚¯ãƒˆãƒ«
attention = np.abs(template_chirin)
# = [0.3, 0, 0.4, 0.3, 0, 0.6, 0.7, 0, 0, 0]

# 3. æ­£è¦åŒ–
attention = attention / 0.7  # maxå€¤ã§å‰²ã‚‹
# = [0.429, 0, 0.571, 0.429, 0, 0.857, 1.000, 0, 0, 0]
#                              â†‘      â†‘
#                        é«˜éŸ³åŸŸã«é«˜ã„æ³¨ç›®åº¦

# 4. MLPã®å‡ºåŠ›ï¼ˆä¾‹ï¼‰
dsp_pred = [-0.3, 0.1, 0.5, 0.5, 0.0, -0.65, -0.85, -0.5, 0.2, -0.05]

# 5. Attentionè£œæ­£ï¼ˆlambda_att = 0.7ï¼‰
corrected = dsp_pred * (1.0 + 0.7 * attention)
#
# eq_highæ¬¡å…ƒï¼ˆ[5]ï¼‰:
#   -0.65 * (1.0 + 0.7 * 0.857)
#   = -0.65 * 1.600
#   = -1.04 â†’ ã‚¯ãƒªãƒƒãƒ—ã—ã¦ -1.0
#
# eq_presenceæ¬¡å…ƒï¼ˆ[6]ï¼‰:
#   -0.85 * (1.0 + 0.7 * 1.000)
#   = -0.85 * 1.700
#   = -1.445 â†’ ã‚¯ãƒªãƒƒãƒ—ã—ã¦ -1.0

# çµæœ: é«˜éŸ³ã‚«ãƒƒãƒˆãŒã‚ˆã‚Šå¼·èª¿ã•ã‚Œã‚‹ï¼
```

**åŠ¹æœã¾ã¨ã‚:**
- ã‚½ãƒ¼ã‚¹ã‚ªãƒãƒãƒˆãƒšã®ç‰¹å¾´çš„ãªæ¬¡å…ƒã®å¤‰åŒ–ãŒ**å¢—å¹…**ã•ã‚Œã‚‹
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œè´ã„ã¦ã„ã‚‹ãƒã‚¤ãƒ³ãƒˆã€ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸå¤‰æ›
- ã‚ˆã‚Š**æ„å›³ã«æ²¿ã£ãŸ**ã€**è‡ªç„¶ãª**å¤‰æ›ãŒå¯èƒ½

---

## å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ—ãƒ­ã‚»ã‚¹

### 7.1 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: RWCP-SSD-Onomatopoeia

**æ§‹æˆ:**
```
training_data_jp_utf8bom.csv
â”œâ”€ audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
â”œâ”€ onomatopoeia: ã‚ªãƒãƒãƒˆãƒšï¼ˆã‚«ã‚¿ã‚«ãƒŠï¼‰
â”œâ”€ confidence: ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä¿¡é ¼åº¦ï¼ˆ1-5ï¼‰
â””â”€ avg_acceptability: å—å®¹åº¦ï¼ˆ1-5ï¼‰
```

**ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:**
```python
df_filtered = df[
    (df['confidence'] >= 4) &          # é«˜ä¿¡é ¼åº¦ã®ã¿
    (df['avg_acceptability'] >= 4.0)   # é«˜å—å®¹åº¦ã®ã¿
]
```

### 7.2 ãƒ‡ãƒ¼ã‚¿æº–å‚™

```python
def create_rwcp_dataset():
    """
    RWCP-SSDãƒ‡ãƒ¼ã‚¿ã‹ã‚‰MLPãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
    """

    # 1. CSVã‚’èª­ã¿è¾¼ã¿
    df = pd.read_csv('training_data_jp_utf8bom.csv')

    # 2. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    df = df[(df['confidence'] >= 4) & (df['avg_acceptability'] >= 4.0)]

    # 3. å„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦
    for idx, row in df.iterrows():
        onomatopoeia = row['onomatopoeia']
        audio_path = row['audio_path']

        # ã‚ªãƒãƒãƒˆãƒšç‰¹å¾´é‡æŠ½å‡º
        Ï† = extract_features(onomatopoeia)

        # ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªDSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆ
        dsp_template = create_dsp_template(onomatopoeia)

        # ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        dataset.append({
            'onomatopoeia': onomatopoeia,
            'audio_path': audio_path,
            'features': Ï†,
            'dsp_params': dsp_template
        })

    return dataset
```

**é‡è¦:** å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã® DSP ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯`create_dsp_template()`ã§**ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã«ç”Ÿæˆ**ã•ã‚Œã¾ã™ã€‚å®Ÿéš›ã®éŸ³å£°ä¿¡å·ã‹ã‚‰æŠ½å‡ºã—ãŸã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

### 7.3 å­¦ç¿’è¨­å®š

```python
# ãƒ¢ãƒ‡ãƒ«
model = Onoma2DSPMLP(d_in=38, d_out=10, hidden_dim=32, use_tanh=True)

# æœ€é©åŒ–
optimizer = Adam(model.parameters(), lr=0.001)
criterion = MSELoss()

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)

# å­¦ç¿’
epochs = 200
for epoch in range(epochs):
    # è¨“ç·´
    for Î”Ï†_batch, Î”DSP_batch in train_loader:
        output = model(Î”Ï†_batch)
        loss = criterion(output, Î”DSP_batch)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # æ¤œè¨¼
    val_loss = evaluate(model, val_loader)
```

---

## å®Ÿè£…ã®è©³ç´°

### 8.1 ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
Tsuji_MLP/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ katakana_to_phoneme.py       # ã‚«ã‚¿ã‚«ãƒŠâ†’éŸ³ç´ 
â”‚   â”‚   â”œâ”€â”€ phoneme_to_mora.py           # éŸ³ç´ â†’ãƒ¢ãƒ¼ãƒ©
â”‚   â”‚   â””â”€â”€ feature_extractor.py         # 38æ¬¡å…ƒç‰¹å¾´é‡æŠ½å‡º
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ mlp_model.py                 # MLPãƒ¢ãƒ‡ãƒ«å®šç¾©
â”‚   â”œâ”€â”€ dsp/
â”‚   â”‚   â””â”€â”€ dsp_engine.py                # DSPå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_loader.py               # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ create_rwcp_dataset.py       # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
â”‚   â”œâ”€â”€ onoma2dsp.py                      # ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ 
â”‚   â”œâ”€â”€ cli.py                            # CLIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
â”‚   â””â”€â”€ train_with_rwcp.py                # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rwcp_model.pth                    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ rwcp_scaler.pkl                   # StandardScaler
â”œâ”€â”€ data/
â”‚   â””â”€â”€ rwcp_dataset.csv                  # å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
â”œâ”€â”€ history/
â”‚   â””â”€â”€ edit_history.json                 # ç·¨é›†å±¥æ­´
â””â”€â”€ output/
    â””â”€â”€ *.wav                             # å‡¦ç†æ¸ˆã¿éŸ³å£°
```

### 8.2 å‡¦ç†ãƒ•ãƒ­ãƒ¼ï¼ˆã‚³ãƒ¼ãƒ‰ä»˜ãï¼‰

```python
# ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ  (onoma2dsp.py)
class Onoma2DSP:
    def process(self, source_onoma, target_onoma, input_audio, output_audio):
        # 1. ã‚ªãƒãƒãƒˆãƒšå‰å‡¦ç†
        source_phonemes = self.katakana_converter.convert(source_onoma)
        target_phonemes = self.katakana_converter.convert(target_onoma)

        source_moras = self.mora_converter.convert(source_phonemes)
        target_moras = self.mora_converter.convert(target_phonemes)

        # 2. ç‰¹å¾´é‡æŠ½å‡º
        Ï†_source = self.feature_extractor.extract_features(
            source_phonemes, source_moras
        )
        Ï†_target = self.feature_extractor.extract_features(
            target_phonemes, target_moras
        )

        # 3. å·®åˆ†è¨ˆç®—
        Î”Ï† = Ï†_target - Ï†_source

        # 4. æ¨™æº–åŒ–
        Î”Ï†_scaled = self.scaler.transform(Î”Ï†.reshape(1, -1))

        # 5. ãƒ¢ãƒ‡ãƒ«æ¨è«–
        Î”Ï†_tensor = torch.FloatTensor(Î”Ï†_scaled)
        with torch.no_grad():
            Î”DSP_norm = self.model(Î”Ï†_tensor).numpy()[0]

        # 6. Amplification
        Î”DSP_norm = np.clip(
            Î”DSP_norm * self.amplification_factor,
            -1.0, 1.0
        )

        # 7. Attentionè£œæ­£
        if self.lambda_att > 0:
            template_source = create_dsp_template(source_onoma)
            attention = np.abs(template_source)
            attention = attention / np.max(attention) if np.max(attention) > 0 else attention

            Î”DSP_norm = Î”DSP_norm * (1.0 + self.lambda_att * attention)
            Î”DSP_norm = np.clip(Î”DSP_norm, -1.0, 1.0)

        # 8. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°
        dsp_params = self.mapper.map_parameters(Î”DSP_norm)

        # 9. DSPå‡¦ç†
        self.dsp_engine.process_audio_file(
            input_audio, output_audio, dsp_params
        )

        return {
            'source_onomatopoeia': source_onoma,
            'target_onomatopoeia': target_onoma,
            'feature_diff_magnitude': float(np.linalg.norm(Î”Ï†)),
            'mapped_params': dsp_params,
            'output_audio': output_audio
        }
```

### 8.3 ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

**å‡¦ç†é€Ÿåº¦:**
- 0.5ç§’ã®éŸ³å£°: ç´„0.7ç§’ã§å‡¦ç†å®Œäº†
- ç‰¹å¾´é‡æŠ½å‡º: <0.01ç§’
- ãƒ¢ãƒ‡ãƒ«æ¨è«–: <0.01ç§’
- DSPå‡¦ç†: éŸ³å£°é•·ã«æ¯”ä¾‹

**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡:**
- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ç´„6KBï¼ˆ1,578ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
- å®Ÿè¡Œæ™‚ãƒ¡ãƒ¢ãƒª: <100MB

**æ¨å¥¨ç’°å¢ƒ:**
- CPU: 2ã‚³ã‚¢ä»¥ä¸Š
- RAM: 2GBä»¥ä¸Š
- Python: 3.8ä»¥ä¸Š

---

## ã¾ã¨ã‚

### ã‚·ã‚¹ãƒ†ãƒ ã®é©æ–°æ€§

1. **å·®åˆ†ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: çµ¶å¯¾çš„ã§ã¯ãªãç›¸å¯¾çš„ãªéŸ³è³ªå¤‰åŒ–ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–
2. **è»½é‡ãªè¨­è¨ˆ**: 1,578ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã§åŠ¹æœçš„ãªå¤‰æ›
3. **Attentionæ©Ÿæ§‹**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è´è¦šçš„æ³¨ç›®ã‚’æ¨å®šã—ã¦è£œæ­£
4. **è§£é‡ˆå¯èƒ½æ€§**: ã‚ªãƒãƒãƒˆãƒšã®éŸ³éŸ»çš„ç‰¹å¾´ã¨éŸ³éŸ¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¯¾å¿œãŒæ˜ç¢º

### æŠ€è¡“çš„ç‰¹å¾´

- **å…¥åŠ›**: 38æ¬¡å…ƒã®éŸ³éŸ»çš„ç‰¹å¾´é‡ï¼ˆ6ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰
- **ãƒ¢ãƒ‡ãƒ«**: è»½é‡MLPï¼ˆ38â†’32â†’10ï¼‰
- **å‡ºåŠ›**: 10æ¬¡å…ƒã®DSPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰åŒ–
- **æ‹¡å¼µ**: Attentionæ©Ÿæ§‹ã«ã‚ˆã‚‹é©å¿œçš„è£œæ­£

### ä½¿ç”¨ã‚·ãƒ¼ãƒ³

- åŠ¹æœéŸ³ã®éŸ³è³ªå¤‰æ›ï¼ˆ0.5ã€œ3ç§’ãŒæœ€é©ï¼‰
- éŸ³æ¥½ãƒ«ãƒ¼ãƒ—ã®åŠ å·¥ï¼ˆ2ã€œ10ç§’ï¼‰
- ç›´æ„Ÿçš„ãªéŸ³å£°ç·¨é›†ï¼ˆã‚ªãƒãƒãƒˆãƒšã§æŒ‡ç¤ºï¼‰

---

**å‚è€ƒæ–‡çŒ®:**
- RWCP-SSD-Onomatopoeia Dataset
- PyTorch Documentation
- Digital Signal Processing Theory

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³å±¥æ­´:**
- v1.0 (2025-12-03): åˆç‰ˆä½œæˆ
